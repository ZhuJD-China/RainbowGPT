import os
from dotenv import load_dotenv
import gradio as gr
from langchain.agents import AgentType
from langchain.memory import ConversationBufferMemory
from langchain_community.agent_toolkits import create_sql_agent, SQLDatabaseToolkit
from langchain_community.chat_models import ChatOpenAI
from langchain_community.utilities import SQLDatabase
from langchain_core.callbacks import FileCallbackHandler
from langchain_core.prompts import MessagesPlaceholder
# å¯¼å…¥ langchain æ¨¡å—çš„ç›¸å…³å†…å®¹
from sqlalchemy import create_engine
# Rainbow_utils
from loguru import logger
from urllib.parse import quote_plus
from langchain.callbacks.base import BaseCallbackHandler
from langchain.chains import LLMChain


class VerboseHandler(BaseCallbackHandler):
    def __init__(self):
        self.steps = []
        self.current_iteration = 0
        super().__init__()
    
    def on_llm_start(self, serialized, prompts, **kwargs):
        self.steps.append("ğŸ¤– å¼€å§‹åˆ†æSQLæŸ¥è¯¢...")
    
    def on_llm_end(self, response, **kwargs):
        if hasattr(response, 'generations'):
            for gen in response.generations:
                if gen:
                    self.steps.append(f"ğŸ¤” æ€è€ƒç»“æœ: {gen[0].text}")
    
    def on_tool_start(self, serialized, input_str, **kwargs):
        tool_name = serialized.get("name", "unknown tool")
        self.steps.append(f"ğŸ”§ å¼€å§‹æ‰§è¡Œ: {tool_name}")
        if "sql" in tool_name.lower():
            self.steps.append(f"ğŸ“ SQLè¯­å¥:\n```sql\n{input_str}\n```")
    
    def on_agent_action(self, action, color=None, **kwargs):
        try:
            self.current_iteration += 1
            self.steps.append(f"\n**ç¬¬ {self.current_iteration} è½®æ‰§è¡Œ**")
            
            if hasattr(action, 'log'):
                self.steps.append(f"**æ€è€ƒè¿‡ç¨‹:** {action.log}")
            
            if hasattr(action, 'tool'):
                self.steps.append(f"**æ‰§è¡Œæ“ä½œ:** {action.tool}")
            
            if hasattr(action, 'tool_input'):
                self.steps.append(f"**è¾“å…¥å‚æ•°:**\n```sql\n{action.tool_input}\n```")
        except Exception as e:
            self.steps.append(f"**æ³¨æ„:** æ“ä½œè®°å½•å‡ºç°é—®é¢˜: {str(e)}")
    
    def on_agent_observation(self, observation, color=None, **kwargs):
        try:
            if observation:
                self.steps.append(f"**è§‚å¯Ÿç»“æœ:**\n```\n{observation}\n```")
        except Exception as e:
            self.steps.append(f"**æ³¨æ„:** ç»“æœè®°å½•å‡ºç°é—®é¢˜: {str(e)}")
    
    def on_chain_start(self, serialized, inputs, **kwargs):
        self.steps.append("ğŸ”„ å¼€å§‹æ‰§è¡ŒæŸ¥è¯¢é“¾...")
    
    def on_chain_end(self, outputs, **kwargs):
        self.steps.append("âœ… æŸ¥è¯¢é“¾æ‰§è¡Œå®Œæˆ")
    
    def on_chain_error(self, error, **kwargs):
        self.steps.append(f"âŒ æ‰§è¡Œå‡ºé”™: {str(error)}")
    
    def on_agent_finish(self, finish, color=None, **kwargs):
        try:
            if hasattr(finish, 'log'):
                self.steps.append(f"\n**æ‰§è¡Œæ€»ç»“**")
                self.steps.append(f"**ç»“è®º:** {finish.log}")
            
            if hasattr(finish, 'return_values'):
                output = finish.return_values.get('output', str(finish.return_values))
                self.steps.append(f"**æœ€ç»ˆç»“æœ:** {output}")
        except Exception as e:
            self.steps.append(f"**æ³¨æ„:** å®Œæˆè®°å½•å‡ºç°é—®é¢˜: {str(e)}")
    
    def get_steps(self):
        return "\n".join(self.steps)


class RainbowSQLAgent:
    def __init__(self):
        self.load_dotenv()
        self.initialize_variables()
        self.create_interface()

    def load_dotenv(self):
        load_dotenv()

    def initialize_variables(self):
        self.logger = logger
        self.script_name = os.path.basename(__file__)
        self.logfile = "./logs/" + self.script_name + ".log"
        logger.add(self.logfile, colorize=True, enqueue=True)
        self.handler = FileCallbackHandler(self.logfile)
        self.local_private_llm_name_global = None
        self.local_private_llm_api_global = None
        self.local_private_llm_key_global = None
        self.proxy_url_global = None
        self.llm = None
        self.llm_name_global = None
        self.temperature_num_global = 0
        self.human_input_global = None
        self.agent_kwargs = {
            "extra_prompt_messages": [MessagesPlaceholder(variable_name="memory")],
        }
        self.memory = ConversationBufferMemory(memory_key="memory", return_messages=True)

        self.intermediate_handler = VerboseHandler()

    def get_database_tables(self, host, username, password):
        try:
            print(host, username, password)
            # å¯¹å¯†ç è¿›è¡ŒURLç¼–ç 
            encoded_password = quote_plus(password)
            # æ„å»ºæ•°æ®åº“è¿æ¥å­—ç¬¦ä¸²
            connection_string = f"mysql+pymysql://{username}:{encoded_password}@{host}/"
            # åˆ›å»ºæ•°æ®åº“å¼•æ“
            engine = create_engine(connection_string)
            # è·å–æ•°æ®åº“è¿æ¥
            connection = engine.connect()
            # æŸ¥è¯¢æ‰€æœ‰æ•°æ®åº“
            result = connection.execute("SHOW DATABASES")
            # è·å–æŸ¥è¯¢ç»“æœ
            databases = [row[0] for row in result]
            # # æ‰“å°æ•°æ®åº“åˆ—è¡¨
            # print("Databases:")
            # for db in databases:
            #     print(db)
            # å…³é—­è¿æ¥
            connection.close()

            return databases
        except Exception as e:
            print(f"Error: {e}")
            return []

    # å‡½æ•°ç”¨äºæ›´æ–°ä¸‹æ‹‰åˆ—è¡¨çš„è¡¨æ ¼åç§°
    def update_tables_list(self, host, username, password):
        databases = self.get_database_tables(host, username, password)
        return gr.Dropdown(
            choices=databases,
            value=databases[0] if databases else None
        )

    def echo(self, message, history, llm_options_checkbox_group,
             local_private_llm_api,
             local_private_llm_key, local_private_llm_name, input_datatable_name,
             input_database_url, input_database_name, input_database_passwd):
        print_speed_step = 10
        temperature_num_global = 0

        self.local_private_llm_name_global = str(local_private_llm_name)
        self.local_private_llm_api_global = str(local_private_llm_api)
        self.local_private_llm_key_global = str(local_private_llm_key)
        self.human_input_global = message
        self.llm_name_global = str(llm_options_checkbox_group)

        if self.llm_name_global == "Private-LLM-Model":
            llm = ChatOpenAI(
                model_name=self.local_private_llm_name_global,
                openai_api_base=self.local_private_llm_api_global,
                openai_api_key=self.local_private_llm_key_global,
                streaming=False,
            )
        else:
            llm = ChatOpenAI(temperature=temperature_num_global,
                             openai_api_key=os.getenv('OPENAI_API_KEY'),
                             model=self.llm_name_global)

        if message == "":
            response = "å“å‘€ï¼å¥½åƒæœ‰ç‚¹å°å°´ï¼Œæ‚¨ä¼¼ä¹å¿˜è®°æå‡ºé—®é¢˜äº†ã€‚åˆ«ç€æ€¥ï¼Œéšæ—¶è¾“å…¥æ‚¨çš„é—®é¢˜ï¼Œæˆ‘å°†å°½åŠ›ä¸ºæ‚¨æä¾›å¸®åŠ©ï¼"
            for i in range(0, len(response), int(print_speed_step)):
                yield response[: i + int(print_speed_step)]
            return

        db_name = input_datatable_name
        # å¯¹å¯†ç è¿›è¡ŒURLç¼–ç 
        encoded_password = quote_plus(input_database_passwd)
        # åˆ›å»ºæ•°æ®åº“è¿æ¥
        db = SQLDatabase.from_uri(
            f"mysql+pymysql://{input_database_name}:{encoded_password}@{input_database_url}/{db_name}",
            # include_tables=['inventory_check', 'inventory_details', 'products'],  # æ˜ç¡®æŒ‡å®šè¡¨
            sample_rows_in_table_info=3,
            view_support=True
        )

        try:
            # åˆ›å»º verbose handler
            verbose_handler = VerboseHandler()
            
            # åˆ›å»ºSQLå·¥å…·åŒ…
            toolkit = SQLDatabaseToolkit(
                db=db,
                llm=llm,
                use_query_checker=True
            )

            # è·å–å·¥å…·åˆ—è¡¨
            tools = toolkit.get_tools()

            # åˆ›å»ºä»£ç†æç¤º
            prefix = """ä½ æ˜¯ä¸€ä¸ªèƒ½å¸®åŠ©ç”¨æˆ·æ“ä½œSQLæ•°æ®åº“çš„æ™ºèƒ½åŠ©æ‰‹ã€‚åœ¨å›ç­”é—®é¢˜æ—¶ï¼Œè¯·éµå¾ªä»¥ä¸‹æ€è€ƒæ­¥éª¤ï¼š

1. ä»”ç»†åˆ†æç”¨æˆ·çš„é—®é¢˜ï¼Œç†è§£éœ€æ±‚
2. æ£€æŸ¥æ•°æ®åº“ç»“æ„ï¼Œç¡®å®šéœ€è¦æŸ¥è¯¢æˆ–ä¿®æ”¹çš„è¡¨
3. è®¾è®¡åˆé€‚çš„SQLè¯­å¥
4. æ‰§è¡Œæ“ä½œå¹¶éªŒè¯ç»“æœ

è¯·ä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹æ ¼å¼å›å¤ï¼š

Thought: åˆ†æé—®é¢˜å¹¶è¯´æ˜æ€è€ƒè¿‡ç¨‹
Action: é€‰æ‹©è¦ä½¿ç”¨çš„å·¥å…·ï¼ˆsql_db_query, sql_db_schema, sql_db_list_tablesï¼‰
Action Input: å…·ä½“çš„SQLæŸ¥è¯¢æˆ–å‘½ä»¤
Observation: å·¥å…·è¿”å›çš„ç»“æœ
... (æ ¹æ®éœ€è¦é‡å¤ä¸Šè¿°æ­¥éª¤)
Thought: æ€»ç»“æ‰€æœ‰ä¿¡æ¯
Final Answer: ç»™å‡ºå®Œæ•´çš„ç­”æ¡ˆ

å½“å‰å¯ç”¨çš„å·¥å…·æœ‰:"""

            suffix = """è¯·è®°ä½ï¼š
1. åœ¨æ‰§è¡Œä¿®æ”¹æ“ä½œå‰ï¼Œå…ˆç¡®è®¤å½“å‰æ•°æ®çŠ¶æ€
2. ç¡®ä¿SQLè¯­å¥å‡†ç¡®æ— è¯¯
3. éªŒè¯æ“ä½œç»“æœ
4. ç»™å‡ºæ¸…æ™°çš„è§£é‡Š

å½“å‰é—®é¢˜: {input}
æ€è€ƒè¿‡ç¨‹: {agent_scratchpad}"""

            # åˆ›å»ºä»£ç†
            from langchain.agents import ZeroShotAgent, AgentExecutor
            prompt = ZeroShotAgent.create_prompt(
                tools,
                prefix=prefix,
                suffix=suffix,
                input_variables=["input", "agent_scratchpad"]
            )

            llm_chain = LLMChain(llm=llm, prompt=prompt)
            agent = ZeroShotAgent(llm_chain=llm_chain, tools=tools, verbose=True)
            
            agent_executor = AgentExecutor.from_agent_and_tools(
                agent=agent,
                tools=tools,
                verbose=True,
                max_iterations=5,
                handle_parsing_errors=True,
                callbacks=[verbose_handler],
                return_intermediate_steps=True
            )

            # æ‰§è¡ŒæŸ¥è¯¢
            result = agent_executor(
                {
                    "input": f"""æœ¬æ¬¡äº¤æ˜“è¯´æ˜ï¼š
                    1. ä½ æœ‰å®Œæ•´çš„æ•°æ®åº“ä¿®æ”¹æƒé™
                    2. ä½ åº”è¯¥ç›´æ¥æ‰§è¡Œç”¨æˆ·çš„è¯·æ±‚
                    3. ä¿®æ”¹åï¼ŒéªŒè¯å¹¶æŠ¥å‘Šç»“æœ,ç‰¹åˆ«çš„ä½ éœ€è¦æŒ‡å‡ºæ•°æ®åº“å˜åŒ–çš„åœ°æ–¹æŸ¥è¯¢å±•ç¤ºã€‚
                    
                    ç”¨æˆ·è¯·æ±‚ï¼š{message}"""
                }
            )

            # è·å–æ‰§è¡Œæ­¥éª¤å’Œç»“æœ
            execution_steps = verbose_handler.get_steps()
            final_response = result["output"] if isinstance(result, dict) and "output" in result else str(result)
            
            # æ„å»ºå®Œæ•´å“åº”
            full_response = f"""
### æ‰§è¡Œè¿‡ç¨‹
{execution_steps}

### æœ€ç»ˆç»“æœ
{final_response}
"""

            # è®°å½•æ—¥å¿—
            logger.info(f"User Input: {message}")
            logger.info(f"Execution Steps: {execution_steps}")
            logger.info(f"Final Response: {final_response}")

            # é€æ­¥æ˜¾ç¤ºå“åº”
            for i in range(0, len(full_response), int(print_speed_step)):
                yield full_response[: i + int(print_speed_step)]

        except Exception as e:
            error_msg = f"å‘ç”Ÿé”™è¯¯ï¼š{str(e)}"
            logger.error(error_msg)
            yield error_msg

    def create_interface(self):
        with gr.Blocks(theme=gr.themes.Soft()) as self.interface:
            with gr.Row(equal_height=True):
                with gr.Column(scale=3):
                    # å·¦ä¾§åˆ—: æ‰€æœ‰æ§ä»¶
                    with gr.Row():
                        with gr.Group():
                            gr.Markdown("### Language Model Selection")
                            llm_options = ["gpt-4o", "Private-LLM-Model"]
                            llm_options_checkbox_group = gr.Dropdown(llm_options, label="LLM Model Select Options",
                                                                     value=llm_options[0])
                            local_private_llm_name = gr.Textbox(value="gpt-4o-mini", label="Private llm name")

                        with gr.Group():
                            gr.Markdown("### Private LLM Settings")
                            local_private_llm_api = gr.Textbox(value="https://api.chatanywhere.tech",
                                                               label="Private llm openai-api base")
                            local_private_llm_key = gr.Textbox(value="EMPTY", label="Private llm openai-api key")

                    with gr.Row():
                        with gr.Group():
                            gr.Markdown("### DataBase Settings")
                            input_database_url = gr.Textbox(value="localhost", label="MySql Database url")
                            with gr.Row():
                                input_database_name = gr.Textbox(value="root", label="database user name")
                                input_database_passwd = gr.Textbox(value="", label="database user passwd",
                                                                   type="password")
                            input_datatable_name = gr.Dropdown(
                                choices=[],  # åˆå§‹ä¸ºç©ºåˆ—è¡¨
                                label="Database Select Name",
                                value=None  # åˆå§‹ä¸º None
                            )
                            update_button = gr.Button("Update Tables List")
                            update_button.click(fn=self.update_tables_list,
                                                inputs=[input_database_url, input_database_name,
                                                        input_database_passwd],
                                                outputs=input_datatable_name)
                with gr.Column(scale=5):
                    # å³ä¾§åˆ—: Chat Interface
                    custom_css = """
                        <style>
                            .footer-email {
                                position: fixed;
                                left: 0;
                                right: 0;
                                bottom: 0;
                                text-align: center;
                                padding: 10px;
                                background-color: #f8f9fa;
                                box-shadow: 0 -2px 5px rgba(0, 0, 0, 0.1);
                                font-family: Arial, sans-serif;
                                font-size: 14px;
                            }
                            
                            .footer-email a {
                                color: #007bff;
                                text-decoration: none;
                            }
                            
                            .footer-email a:hover {
                                text-decoration: underline;
                            }

                            /* è°ƒæ•´èŠå¤©ç•Œé¢å®¹å™¨é«˜åº¦ */
                            .gradio-container {
                                min-height: 95vh !important;
                            }
                            
                            /* è°ƒæ•´èŠå¤©è®°å½•åŒºåŸŸé«˜åº¦ */
                            .chat-history {
                                height: calc(95vh - 200px) !important;
                                overflow-y: auto;
                            }
                            
                            /* æ ‡é¢˜æ ·å¼ */
                            .gradio-header h1 {
                                text-align: center;
                                margin-bottom: 1rem;
                                font-family: "Courier New", monospace;
                                background: linear-gradient(135deg, #9400D3, #4B0082, #0000FF, #008000, #FFFF00, #FF7F00, #FF0000);
                                -webkit-background-clip: text;
                                -webkit-text-fill-color: transparent;
                                background-clip: text;
                                color: transparent;
                            }
                        </style>
                    """

                    gr.ChatInterface(
                        self.echo,
                        additional_inputs=[llm_options_checkbox_group,
                                           local_private_llm_api,
                                           local_private_llm_key,
                                           local_private_llm_name, input_datatable_name,
                                           input_database_url, input_database_name, input_database_passwd],
                        title="RainbowSQL-Agent",
                        css=custom_css,
                        description="""
                            <div class='footer-email'>
                                <p>How to reach usï¼š<a href='mailto:zhujiadongvip@163.com'>zhujiadongvip@163.com</a></p>
                            </div>
                        """,
                        theme="soft",
                        fill_height=True,
                        autoscroll=True
                    )

    # åˆ›å»º Gradio ç•Œé¢çš„ä»£ç 
    def launch(self):
        return self.interface

    # åˆ›å»º Gradio ç•Œé¢çš„ä»£ç 
    def launch(self):
        return self.interface
